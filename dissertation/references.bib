% Example references for Parallax dissertation

@article{blelloch1996programming,
  title={Programming parallel algorithms},
  author={Blelloch, Guy E},
  journal={Communications of the ACM},
  volume={39},
  number={3},
  pages={85--97},
  year={1996},
  publisher={ACM New York, NY, USA}
}

@inproceedings{chakravarty2007data,
  title={Data parallel Haskell: a status report},
  author={Chakravarty, Manuel MT and Leshchinskiy, Roman and Peyton Jones, Simon and Keller, Gabriele and Marlow, Simon},
  booktitle={Proceedings of the 2007 workshop on Declarative aspects of multicore programming},
  pages={10--18},
  year={2007}
}

@article{Lee2006TheProblem,
  title={The problem with threads},
  author={Lee, Edward A},
  journal={Computer},
  volume={39},
  number={5},
  pages={33--42},
  year={2006},
  publisher={IEEE}
}

@inproceedings{odersky2004overview,
  title={An overview of the Scala programming language},
  author={Odersky, Martin and Altherr, Philippe and Cremet, Vincent and Emir, Burak and Maneth, Sebastian and Micheloud, St{\'e}phane and Mihaylov, Nikolay and Schinz, Michel and Stenman, Erik and Zenger, Matthias},
  booktitle={EPFL Technical Report},
  year={2004}
}

@article{sutter2005free,
  title={The free lunch is over: A fundamental turn toward concurrency in software},
  author={Sutter, Herb},
  journal={Dr. Dobb's journal},
  volume={30},
  number={3},
  pages={202--210},
  year={2005}
}

@inproceedings{isard2007dryad,
  title={Dryad: distributed data-parallel programs from sequential building blocks},
  author={Isard, Michael and Budiu, Mihai and Yu, Yuan and Birrell, Andrew and Fetterly, Dennis},
  booktitle={Proceedings of the 2nd ACM SIGOPS/EuroSys European Conference on Computer Systems 2007},
  pages={59--72},
  year={2007}
}

@inproceedings{zaharia2010spark,
  title={Spark: Cluster computing with working sets},
  author={Zaharia, Matei and Chowdhury, Mosharaf and Franklin, Michael J and Shenker, Scott and Stoica, Ion},
  booktitle={2nd USENIX workshop on hot topics in cloud computing (HotCloud 10)},
  year={2010}
}

@article{dean2008mapreduce,
  title={MapReduce: simplified data processing on large clusters},
  author={Dean, Jeffrey and Ghemawat, Sanjay},
  journal={Communications of the ACM},
  volume={51},
  number={1},
  pages={107--113},
  year={2008},
  publisher={ACM New York, NY, USA}
}

@inproceedings{chambers2010flumejava,
  title={FlumeJava: easy, efficient data-parallel pipelines},
  author={Chambers, Craig and Raniwala, Ashish and Perry, Frances and Adams, Stephen and Henry, Robert R and Bradshaw, Robert and Weizenbaum, Nathan},
  booktitle={Proceedings of the 31st ACM SIGPLAN conference on Programming language design and implementation},
  pages={363--375},
  year={2010}
}

@inproceedings{gordon2006exploiting,
  title={Exploiting coarse-grained task, data, and pipeline parallelism in stream programs},
  author={Gordon, Michael I and Thies, William and Amarasinghe, Saman},
  booktitle={Proceedings of the 12th international conference on Architectural support for programming languages and operating systems},
  pages={151--162},
  year={2006}
}

@article{backus1978can,
  title={Can programming be liberated from the von Neumann style? A functional style and its algebra of programs},
  author={Backus, John},
  journal={Communications of the ACM},
  volume={21},
  number={8},
  pages={613--641},
  year={1978},
  publisher={ACM New York, NY, USA}
}

@inproceedings{wadler1990comprehending,
  title={Comprehending monads},
  author={Wadler, Philip},
  booktitle={Proceedings of the 1990 ACM conference on LISP and functional programming},
  pages={61--78},
  year={1990}
}

@inproceedings{peyton2001composing,
  title={Composing reactive animations},
  author={Peyton Jones, Simon and Finne, Sigbjorn and Wan, Zhixiong and Thomsen, Bjarne and Gray, Philip and Meijer, Erik},
  booktitle={Functional Programming},
  year={2001}
}

@article{hughes1989functional,
  title={Why functional programming matters},
  author={Hughes, John},
  journal={The computer journal},
  volume={32},
  number={2},
  pages={98--107},
  year={1989},
  publisher={Oxford University Press}
}

@inproceedings{lattner2004llvm,
  title={LLVM: A compilation framework for lifelong program analysis \& transformation},
  author={Lattner, Chris and Adve, Vikram},
  booktitle={International Symposium on Code Generation and Optimization, 2004. CGO 2004.},
  pages={75--86},
  year={2004},
  organization={IEEE}
}

@inproceedings{milner1978theory,
  title={A theory of type polymorphism in programming},
  author={Milner, Robin},
  booktitle={Journal of computer and system sciences},
  volume={17},
  number={3},
  pages={348--375},
  year={1978}
}

@article{lafont1990interactionnets,
  title={Interaction nets},
  author={Lafont, Yves},
  journal={Proceedings of the 17th ACM SIGPLAN-SIGACT symposium on Principles of programming languages},
  pages={95--108},
  year={1990},
  publisher={Elsevier}
}

@article{mazza,
  title={Interaction Combinators: Observational Equivalence and Full Abstraction},
  author={Mazza, Damiano},
  journal={Electronic Notes in Theoretical Computer Science},
  volume={20},
  pages={75--94},
  year={1999},
  publisher={Elsevier}
}

@misc{BendGithub,
  title={Bend: A Language for Implicit Parallel Computation},
  author={HigherOrderCO},
  howpublished={\url{https://github.com/HigherOrderCO/Bend}},
  year={2023},
  note={Accessed: 2024-03-03}
}

@techreport{Asanovic2006TheLandscape,
    Author= {AsanoviÄ‡, Krste and Bodik, Ras and Catanzaro, Bryan Christopher and Gebis, Joseph James and Husbands, Parry and Keutzer, Kurt and Patterson, David A. and Plishker, William Lester and Shalf, John and Williams, Samuel Webb and Yelick, Katherine A.},
    Title= {The Landscape of Parallel Computing Research: A View from Berkeley},
    Year= {2006},
    Month= {Dec},
    Url= {http://www2.eecs.berkeley.edu/Pubs/TechRpts/2006/EECS-2006-183.html},
    Number= {UCB/EECS-2006-183},
    Abstract= {The recent switch to parallel microprocessors is a milestone in the history of computing. Industry has laid out a roadmap for multicore designs that preserves the programming paradigm of the past via binary compatibility and cache coherence. Conventional wisdom is now to double the number of cores on a chip with each silicon generation. A multidisciplinary group of Berkeley researchers met nearly two years to discuss this change. Our view is that this evolutionary approach to parallel hardware and software may work from 2 or 8 processor systems, but is likely to face diminishing returns as 16 and 32 processor systems are realized, just as returns fell with greater instruction-level parallelism. We believe that much can be learned by examining the success of parallelism at the extremes of the computing spectrum, namely embedded computing and high performance computing. This led us to frame the parallel landscape with seven questions, and to recommend the following: \begin{itemize} \item The overarching goal should be to make it easy to write programs that execute efficiently on highly parallel computing systems \item The target should be 1000s of cores per chip, as these chips are built from processing elements that are the most efficient in MIPS (Million Instructions per Second) per watt, MIPS per area of silicon, and MIPS per development dollar. \item Instead of traditional benchmarks, use 13 "Dwarfs" to design and evaluate parallel programming models and architectures. (A dwarf is an algorithmic method that captures a pattern of computation and communication.) \item "Autotuners" should play a larger role than conventional compilers in translating parallel programs. \item To maximize programmer productivity, future programming models must be more human-centric than the conventional focus on hardware or applications. \item To be successful, programming models should be independent of the number of processors. \item To maximize application efficiency, programming models should support a wide range of data types and successful models of parallelism: task-level parallelism, word-level parallelism, and bit-level parallelism. \item Architects should not include features that significantly affect performance or energy if programmers cannot accurately measure their impact via performance counters and energy counters. \item Traditional operating systems will be deconstructed and operating system functionality will be orchestrated using libraries and virtual machines. \item To explore the design space rapidly, use system emulators based on Field Programmable Gate Arrays (FPGAs) that are highly scalable and low cost. \end{itemize} Since real world applications are naturally parallel and hardware is naturally parallel, what we need is a programming model, system software, and a supporting architecture that are naturally parallel. Researchers have the rare opportunity to re-invent these cornerstones of computing, provided they simplify the efficient programming of highly parallel systems.},
}

@article{Berzal2013,
author = {Berzal, Fernando},
year = {2013},
month = {03},
pages = {35-39},
title = {Structured parallel programming by Michael McCool, James Reinders {\&} Arch Robison},
volume = {38},
journal = {ACM SIGSOFT Software Engineering Notes},
doi = {10.1145/2439976.2439995}
}

@incollection{McCool2012StructuredParallel,
editor = {Michael McCool and Arch D. Robison and James Reinders},
booktitle = {Structured Parallel Programming},
publisher = {Morgan Kaufmann},
address = {Boston},
pages = {391-396},
year = {2012},
isbn = {978-0-12-415993-8},
doi = {https://doi.org/10.1016/B978-0-12-415993-8.00044-X},
url = {https://www.sciencedirect.com/science/article/pii/B978012415993800044X}
}

@article{PeytonJones2003Haskell,
author = {Peyton Jones, Simon},
year = {2003},
month = {01},
pages = {},
title = {Haskell 98 Language and Libraries: the Revised Report},
volume = {13},
journal = {Journal of Functional Programming}
}

@phdthesis{Henriksen2017Futhark,
  author       = {Troels Henriksen},
  title        = {Design and Implementation of the Futhark Programming Language},
  school       = {University of Copenhagen},
  year         = 2017,
  address      = {Universitetsparken 5, 2100 K{\o}benhavn},
  month        = 11,
}
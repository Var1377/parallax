\chapter{Implementation}

\section{Introduction}
% Purpose: Briefly state the chapter's purpose (detailing the implementation of Parallax), reiterate the core goal (automatic parallelism via INs), and outline the chapter's structure (compiler pipeline, runtime, tooling).
% Questions:
% - What is the main achievement described in this chapter? (e.g., "This chapter details the implementation of the Parallax compiler and parallel runtime...")
% A: Infer from introduction
% - What is the core technical approach? (...which enables automatic parallelism by compiling a functional language to interaction nets.")
% A: Infer from introduction
% - What are the major components covered? (e.g., "We will cover the compiler pipeline stages, the parallel runtime architecture based on partition ownership, GC integration, and supporting tooling.")
% A: Infer from crates/README.md
This chapter details the concrete implementation of the Parallax system, encompassing the compiler and the parallel runtime environment designed to execute Parallax programs. As established in the introduction, the central goal of Parallax is to achieve automatic, efficient parallelism by compiling a high-level functional language to interaction nets. We will describe the journey from source code to execution, covering the stages of the compiler pipeline (frontend parsing, resolution, type checking, intermediate representations, and backend code generation), the architecture of the parallel runtime based on partition ownership, the integration of garbage collection, and the supporting tooling developed for the project.

\section{Implementation Philosophy and Approach}
% Purpose: Briefly recap the high-level methodology and technology choices established in the Preparation chapter that guided the implementation.
% Questions:
% - What was the primary programming language and why was it chosen? (Rust - safety, performance, concurrency?)
% A: Those + a rich programming language development ecosystem. My language also looks like Rust so I can refer to rustc and rust-analyzer for inspiration.
% - What was the overall project structure? (Multi-crate Cargo workspace - modularity, parallel builds?)
% A: Yes
% - What core frameworks were decided upon early? (Salsa - incrementality? Tree-sitter - parsing?)
% A: Probably don't talk about it here.
% - What was the development methodology? (Iterative? Test-driven elements?)
% A: That's in @preparation.tex
The implementation of Parallax was guided by decisions made during the preparation phase (Chapter 2). The primary programming language chosen was Rust, selected for its strong compile-time safety guarantees (particularly around memory and concurrency), its potential for high performance competitive with C/C++, its rich ecosystem supporting compiler development, and its first-class concurrency features. Furthermore, the syntactic and semantic similarities between Parallax and Rust allowed for leveraging insights and architectural patterns from mature Rust projects like the Rust compiler (`rustc`) and `rust-analyzer`.

Architecturally, the project adopted a multi-crate Cargo workspace structure from the outset. This modular design, detailed further in the Repository Overview, was chosen to enforce clear separation of concerns between compiler stages, facilitate parallel compilation during development, enhance testability of individual components, and improve overall maintainability. The development methodology followed the hybrid approach outlined in Section~\ref{sec:prep_software_eng}, combining upfront architectural planning with iterative refinement of individual components.

\section{Repository Overview}
% Purpose: Describe the high-level structure of the source code repository, identify key crates and external dependencies, and explain the rationale for using specific tools/libraries. Acknowledge that the project was built from scratch. Fulfills a specific mark scheme requirement.
% Questions:
% - Was the code written from scratch?
% A: Yes
% - How is the codebase organized? (Multi-crate Cargo workspace?)
% A: Infer from crates/README.md, but yep exactly
% - What are the main crates and their roles? (List `parallax-source`, `syntax`, `resolve`, `types`, `hir`, `mir`, `native`, `codegen`, `net`, `rt`, `db`, `cli`, `tree-sitter-parallax`. Briefly describe each's function in the pipeline/system. Maybe use a table?)
% A: Infer from crates/README.md. If possible to a full diagram, that'd be great
% - What are the most important external libraries/tools used? (Tree-sitter, Salsa, Cranelift, Crossbeam, rsgc, repc, clap, miette, parking_lot, slab, etc.)
% A: All of those. If I remember more I can add them in later.
% - Why were these specific external tools/libraries chosen? (Justify based on capabilities, e.g., Salsa for incrementality, Cranelift for JIT/Rust integration, Crossbeam for concurrency primitives.)
% A: Maybe we get to that in later chapters? There are a lot of dependencies so maybe listing things outside of salsa, miette, clap and thiserror might be a bit much.
The entire Parallax codebase was developed from scratch for this project. The source code is organized within a standard Rust multi-crate Cargo workspace. The top-level directory structure relevant to the implementation is approximately as follows:

\begin{verbatim}
parallax/
├── Cargo.toml        # Workspace definition
├── README.md         # Top-level project description
├── crates/           # Directory containing all core implementation crates
│   ├── parallax-cli/
│   ├── parallax-codegen/
│   ├── parallax-db/      # Salsa database orchestration
│   ├── parallax-effects/ # Effect system (Planned/WIP)
│   ├── parallax-gc/      # GC integration utilities
│   ├── parallax-hir/     # High-level IR
│   ├── parallax-hvm/     # HVM integration (Planned/WIP)
│   ├── parallax-mir/     # Mid-level IR
│   ├── parallax-native/  # Native backend (Cranelift)
│   ├── parallax-net/     # Parallel runtime
│   ├── parallax-resolve/ # Name resolution
│   ├── parallax-rt/      # Unified runtime
│   ├── parallax-source/  # Source loading & frame management
│   ├── parallax-stdlib/  # Standard library definitions
│   ├── parallax-syntax/  # Parsing & AST
│   ├── parallax-types/   # Type checking
│   ├── parallax-utils/   # Shared utilities
│   └── tree-sitter-parallax/ # Language grammar
├── dissertation/     # Dissertation source files
│   └── chapters/
│       └── implementation.tex # This chapter
├── ...               # Other files (tests, docs, etc.)
\end{verbatim}

This structure promotes modularity and separates the distinct phases of the compiler and runtime system. Figure~\ref{fig:impl_pipeline} illustrates the high-level compilation pipeline, showing the flow of data representations and the primary crate responsible for each transformation.

% TikZ diagram adapted from crates/README.md
\begin{figure}[h!]
    \centering
    \begin{tikzpicture}[node distance=1.2cm and 0.8cm, auto, >=Latex,
        data/.style={rectangle, draw, text centered, rounded corners, minimum height=2em, text width=11em},
        crate/.style={text width=5em, font=\scriptsize\ttfamily, align=center},
        arrow/.style={->, thick}]

        % Nodes for data stages
        \node (source) [data] {Source Code \\ (Files + frame.toml)};
        \node (frame) [data, below=of source] {Frame \\ (Config + Source Files)};
        \node (ast) [data, below=of frame] {ModuleStructure \\ (AST + Errors)};
        \node (resolved) [data, below=of ast] {ResolvedModule \\ (Resolved Defs + Scopes)};
        \node (typed) [data, below=of resolved] {TypedModule \\ (Typed Defs + AST)};
        \node (hir) [data, below=of typed] {HirModule \\ (ANF HIR + Opts)};
        \node (mir) [data, below left=of hir] {MirGraph};
        \node (native) [data, right=of hir, xshift=2cm] {CompiledArtifact \\ (Native Code)}; % Moved right
        \node (net) [data, below=of mir] {Reduced Net};
        \node (runtime) [data, below right=of hir, yshift=-2.4cm, xshift=2cm] {Runtime Execution}; % Positioned below native/net
        \node (result) [data, below=of runtime] {Final Result};

        % Arrows with crate labels
        \draw [arrow] (source) -- node[crate, right] {parallax-source} (frame);
        \draw [arrow] (frame) -- node[crate, right] {parallax-syntax} (ast);
        \draw [arrow] (ast) -- node[crate, right] {parallax-resolve} (resolved);
        \draw [arrow] (resolved) -- node[crate, right] {parallax-types} (typed);
        \draw [arrow] (typed) -- node[crate, right] {parallax-hir} (hir);

        % Branching from HIR
        \draw [arrow] (hir) -| node[crate, above, pos=0.25] {parallax-native} (native);
        \draw [arrow] (hir) -- node[crate, left] {parallax-mir} (mir);

        % MIR to Net
        \draw [arrow] (mir) -- node[crate, left] {parallax-net} (net);

        % Codegen Orchestrator (Conceptual annotation)
        \node[draw=none, fill=none, text width=6em, align=center, font=\tiny, below right=0.1cm and -0.5cm of hir] (codegen) {(Orchestrated by \\ \texttt{parallax-codegen})};

        % Backends to Runtime
        \draw [arrow] (native) |- (runtime);
        \draw [arrow] (net) |- (runtime);
        \node[draw=none, fill=none, text width=6em, align=center, font=\tiny, right=0.1cm of runtime] (rt_crate) {(\texttt{parallax-rt})};

        % Runtime to Result
        \draw [arrow] (runtime) -- (result);

        % HVM Path (Optional, as described in README)
        \node (hvm) [crate, below right=of mir, yshift=-0.5cm] {parallax-hvm};
        \draw [arrow, dashed] (hvm) -> (net);


    \end{tikzpicture}
    \caption{Parallax Compilation Pipeline and Crate Responsibilities}
    \label{fig:impl_pipeline}
\end{figure}

The listed crates represent the core compiler stages and runtime components. Each crate's specific role is detailed further in subsequent sections.

While built from scratch, the implementation leverages several powerful external Rust libraries to accelerate development and ensure robustness. Key dependencies include:
\begin{itemize}
    \item \textbf{Tree-sitter}: Used via the \texttt{tree-sitter} crate for robust, error-tolerant parsing based on the custom \texttt{tree-sitter-parallax} grammar. Chosen for its maturity and incremental parsing capabilities.
    \item \textbf{Salsa}: The \texttt{salsa} crate provides the incremental computation framework underpinning the compiler database (`parallax-db`). Chosen for its proven effectiveness in projects like `rust-analyzer` for achieving efficient recompilation.
    \item \textbf{Cranelift}: The \texttt{cranelift-* } family of crates is used in \texttt{parallax-native} for Just-in-Time (JIT) compilation to native code. Chosen for its Rust implementation, ease of integration compared to LLVM, and good performance potential.
    \item \textbf{Crossbeam}: Provides essential high-performance concurrency primitives (e.g., \texttt{crossbeam-deque}, \texttt{crossbeam-channel}) likely used in \texttt{parallax-net} for implementing the work-stealing scheduler. Chosen for its efficiency and suitability for building parallel systems.
    \item \textbf{clap}: Used in \texttt{parallax-cli} for parsing command-line arguments. Chosen for its feature-richness and widespread adoption in the Rust ecosystem.
    \item \textbf{miette}: Provides the framework for rich diagnostic error reporting throughout the compiler. Chosen for its ability to produce user-friendly, informative error messages with source context.
    \item \textbf{thiserror}: Used extensively for defining custom error types boilerplate-free.
\end{itemize}
This list highlights some of the most significant external libraries, but the project relies on numerous others (such as \texttt{rsgc} for garbage collection, \texttt{repc} for type layout computation, \texttt{parking\_lot} for efficient locking primitives, \texttt{slab} for memory allocation, \texttt{serde} and \texttt{toml} for configuration, and \texttt{fxhash} for hashing, among others) which provide crucial supporting functionality. The effective use of these well-established libraries allowed development to focus on the novel aspects of the Parallax compiler and runtime architecture.

\section{Compiler Implementation: Frontend and Resolution}
% Purpose: Detail the implementation of the initial compiler stages that transform source text into a resolved and typed representation.
% Questions:
% - How does each frontend stage contribute to the compilation process?

\subsection{Source Management (`parallax-source`)}
% Purpose: Describe how source files and project configuration (`frame.toml`) are loaded and managed incrementally.
% Questions:
% - How are Frames and `frame.toml` loaded and represented?
% - How is Salsa used here to track file/config changes? (`SourceFile`, `Frame`, `Dir`, `FrameConfig` tracked/input structs?)
% - How are errors handled during loading? (`ParallaxDiagnostic` accumulator?)

\subsection{Parsing (`parallax-syntax`)}
% Purpose: Describe the process of converting source text into an Abstract Syntax Tree (AST).
% Questions:
% - What parsing library/technique is used? (Tree-sitter with `tree-sitter-parallax` grammar?)
% - What are the key AST structures defined? (`Item`, `Expr`, `Type`, `Pattern` etc. + `ModuleUnit`/`ModuleStructure`?)
% - How are parsing errors captured and reported? (Integration with `miette`?)
% - How does Salsa enable incremental parsing? (`parse_file`, `frame_module_structure` queries?)

\subsection{Name Resolution (`parallax-resolve`)}
% Purpose: Describe how identifiers are resolved to their definitions and scopes are built.
% Questions:
% - How are names (variables, functions, types) linked to their declarations? (Symbol table? Scope tracking?)
% - How are imports (`use` statements) handled?
% - What is the output of this stage? (`ResolvedModuleStructure` containing resolved symbols?)
% - How does Salsa integrate here? (`ResolveDatabase` trait, queries?)

\subsection{Type Checking (`parallax-types`)}
% Purpose: Describe the type inference and checking process, including trait resolution.
% Questions:
% - What type system/algorithm is used? (Hindley-Milner based?)
% - How are types represented internally? (`Ty`, `TyKind`?)
% - How is type inference performed? (`InferenceContext`, unification?)
% - How are traits defined and implementations resolved? (`TraitRepository`?)
% - What is the output? (`TypedModule`, `TypedDefinitions`, containing typed ASTs?)
% - How does Salsa integrate? (`TypeDatabase` trait, `type_check_definitions` query?)

\section{Compiler Implementation: Intermediate Representations}
% Purpose: Describe the design and role of the Intermediate Representations (IRs) used between the frontend and backends.
% Questions:
% - Why are these specific IRs necessary? What purpose does each serve?

\subsection{High-Level IR (`parallax-hir`)}
% Purpose: Describe the HIR, its structure (ANF), and any optimizations performed at this level.
% Questions:
% - What is the structure of the HIR? (A-Normal Form? Explicit types? Symbol-based?)
% - How is it generated from the typed AST? (`lower_to_hir`?)
% - What optimizations are performed on the HIR? (DCE? Inlining? Describe the algorithms briefly.)
% - Why was ANF chosen? (Simplifies subsequent passes?)

\subsection{Mid-Level IR (`parallax-mir`)}
% Purpose: Describe the MIR, focusing on its graph-based nature, data flow, and suitability for interaction net generation.
% Questions:
% - What is the structure of the MIR? (Graph-based? Nodes like `Constructor`, `Switch`, `Duplicator`, `Eraser`?)
% - How does it represent data flow and resource usage explicitly? (Usage analysis pass? `Duplicator`/`Eraser` nodes?)
% - How is it generated from the HIR?
% - Why was this specific MIR design chosen? (Closer to the interaction net model?)

\section{Compiler Implementation: Backends and Code Generation}
% Purpose: Detail how the IRs are translated into executable forms (native code and interaction nets).
% Questions:
% - What are the target execution models? (Native machine code, Interaction Net Runtime?)

\subsection{Native Backend (`parallax-native`)}
% Purpose: Describe the compilation to native machine code using Cranelift JIT. Focus on GC integration and other key features.
% Questions:
% - What is the target codegen library? (Cranelift JIT?)
% - How is HIR translated to Cranelift IR?
% - How was Garbage Collection integrated? (Describe the interaction with `rsgc`: FFI calls? Shadow stack mechanism? Global roots? What were the challenges?)
% - How are type layouts calculated? (`repc`? Manual enum layout?)
% - Were specific optimizations like Tail Call Optimization (TCO) implemented here?
% - What is the final output? (`CompiledArtifact`?)
% - Why was this backend implemented? (Performance baseline? Efficient sequential execution?)

\subsection{Interaction Net Backend (Targeting `parallax-net`)}
% Purpose: Describe the process of generating the interaction net representation suitable for the parallel runtime. Address the reduction recognition challenge.
% Questions:
% - How is the MIR lowered/translated into the graph format used by `parallax-net`?
% - How does the implementation solve the "reduction recognition" problem? (How does the system know when inputs to native intrinsics are fully reduced and ready?)
% - How does this backend enable the core goal of automatic parallelism?
% - What are the key node types generated for the runtime? (Connect back to MIR nodes if possible)

\subsection{Orchestration (`parallax-codegen`)}
% Purpose: Describe the role of this crate in selecting and coordinating the backend(s).
% Questions:
% - How does this crate decide which backend(s) to invoke? (Currently just native?)
% - What is its input and output? (`HirModule` -> `CompiledOutput`?)
% - Why is this separate orchestration layer useful? (Architectural separation? Future flexibility?)

\section{Parallel Runtime Implementation (`parallax-net`)}
% Purpose: Detail the architecture and implementation of the core parallel interaction net reduction engine. This is a crucial section.
% Questions:
% - What is the overall model for parallel reduction? (Partition Ownership?)
% - How does this model contrast with alternatives (e.g., HVM's global atomics)? Why was it chosen? (Scalability? Locality?)

\subsection{Runtime Architecture (Partition Ownership)}
% Purpose: Describe the main components (Runtime, Partition, Worker) and how they coordinate work.
% Questions:
% - What are the roles of the `Runtime`, `Partition`, and `Worker` components?
% - How is work distributed? (Work-stealing queues? Using `crossbeam`?)
% - How is partition ownership managed and transferred?

\subsection{Node Representation and Memory Management}
% Purpose: Describe how interaction net nodes are stored and managed, including GC interaction.
% Questions:
% - What are the main node types implemented in the runtime? (`Constructor`, `Duplicator`, `Ref`, `Number`, `Switch`, `Async` - what does each do?)
% - How are nodes allocated and stored within partitions? (Slab allocation using `slab` crate?)
% - How does the runtime interact with the Garbage Collector (`rsgc`)? (How are roots identified within the net? How are GC pauses coordinated with worker activity?) What challenges arose?
% - Why was slab allocation chosen? (Efficiency? Locality?)

\subsection{Reduction Engine and Concurrency}
% Purpose: Describe how interaction rules are applied, how cross-partition interactions are handled, and any concurrency issues faced.
% Questions:
% - How are interaction rules applied within a worker's owned partition?
% - How are interactions that cross partition boundaries handled? (What synchronization is needed?)
% - Were there specific concurrency bugs encountered during implementation? How were they fixed? (e.g., issues with shared state, race conditions - use of `parking_lot` locks, `ThreadLocal`?)

\section{Tooling Implementation (`parallax-cli`)}
% Purpose: Describe the implementation of the command-line interface.
% Questions:
% - What commands does the CLI provide? (`new`, `build`, `run`, `check`, `clean`?)
% - How were command-line arguments parsed? (`clap`?)
% - How does the CLI interact with the compiler core? (Using `parallax-db`?)
% - What is the purpose of the CLI? (User interface, project management?)

\section{Design Strategies for Testing}
% Purpose: Briefly describe the approach taken to testing the implementation (unit tests, integration tests, frameworks). Demonstrates a professional approach.
% Questions:
% - How was the code tested? (Unit tests per crate? Integration tests for the pipeline/runtime?)
% - Did the multi-crate structure help with testing?
% - Were any specific testing frameworks or helper scripts developed? (e.g., automated benchmarks, test case generators?)

\section{Summary}
% Purpose: Briefly summarise the key components implemented and how they contribute to the overall project goals.
% Questions:
% - What were the major pieces of software built? (Compiler stages, parallel runtime, CLI?)
% - What are the key technical achievements of the implementation? (e.g., Partition ownership runtime, GC integration with INs, ANF-based HIR?)
% - How does the implemented system meet the project's aims? (Relate back to automatic parallelism, efficiency goals.)

% --- End of Structure --- 
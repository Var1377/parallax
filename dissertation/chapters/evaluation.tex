\chapter{Evaluation}
% This chapter presents evidence of system performance and goal achievement, maintaining a rigorous, professional standard.

\section{Introduction and Success Criteria Recap} % 4.1
This chapter evaluates the Parallax system against the goals established in Chapter 2. The primary success criterion, refined from the initial proposal, was to demonstrate **improved memory performance** (specifically footprint and churn) compared to existing interaction net implementations like Bend, leveraging the novel runtime architecture and memory management strategies. A secondary criterion was to achieve **effective parallel scaling** on multi-core processors, showcasing the benefits of the automatic parallelization inherent in the interaction net model and the chosen Partition Ownership runtime design (intended for `parallax-rt`). Correctness of the compiler and runtime is a foundational requirement. This evaluation aims to provide quantitative and qualitative evidence to assess the extent to which these criteria were met.

\section{Evaluation Methodology} % 4.2 (Was 4.1)
% Discuss the methodology used for evaluation

\subsection{Benchmark Suite} % 4.2.1
To evaluate memory usage and parallel scaling, a suite of benchmarks was selected, including:
\begin{itemize}
    \item [TODO: List 2-4 specific benchmarks used, e.g., Merge Sort, Matrix Multiplication (if applicable), N-body simulation, potentially a lambda calculus evaluator]. 
    \item [TODO: Briefly justify *why* these benchmarks were chosen - e.g., known parallelizable algorithms, different memory access patterns, used in related work like Bend's evaluation].
\end{itemize}
These benchmarks were implemented in Parallax. Where feasible, equivalent sequential versions (in Parallax or C/Rust) and versions for the baseline comparison system (Bend) were used.

\subsection{Metrics} % 4.2.2
The following metrics were collected:
\begin{itemize}
    \item \textbf{Memory Footprint:} Peak resident memory usage, measured using [TODO: Specify tool, e.g., `/usr/bin/time -v`, Valgrind Massif, or internal instrumentation].
    \item \textbf{Memory Churn:} Total allocations/bytes allocated or a similar proxy metric indicating memory allocation activity, measured using [TODO: Specify tool, e.g., Valgrind Massif/DHAT, internal allocator stats].
    \item \textbf{Execution Time:} Wall-clock time for benchmark completion, measured using [TODO: Specify tool/method, e.g., internal timing, `hyperfine`].
    \item \textbf{Parallel Speedup:} Ratio of sequential execution time to parallel execution time ($Speedup = T_{sequential} / T_{parallel}(N)$) for varying core counts $N$.
    \item \textbf{Parallel Efficiency:} Speedup divided by the number of cores ($Efficiency = Speedup / N$).
    \item \textbf{Correctness:} Verified by comparing the output of Parallax executions against known correct outputs from sequential versions or reference implementations.
\end{itemize}

\subsection{Experimental Setup} % 4.2.3
All experiments were conducted on the following system:
\begin{itemize}
    \item \textbf{Hardware:} [TODO: Specify CPU model, number of cores/threads, RAM amount, Cache sizes].
    \item \textbf{Software:} [TODO: Specify Operating System (e.g., Linux distribution/version), Rust compiler version (e.g., `rustc 1.XX.X`), Parallax version (commit hash), Bend version (if used), C/Rust compiler version (if used)].
\end{itemize}
Measurements for timing and memory were typically averaged over [TODO: Specify number, e.g., 5-10] runs after discarding initial warm-up runs to ensure cache stability. [TODO: Mention if confidence intervals were calculated/shown].

\subsection{Comparison Points} % 4.2.4
Performance was compared against:
\begin{itemize}
    \item **Sequential Parallax:** The same Parallax code run on a single core (or with parallelism disabled).
    \item **Bend Runtime:** [TODO: Specify version] executing equivalent benchmark implementations [TODO: Mention source of Bend benchmarks, e.g., adapted from Parallax or existing Bend examples]. This serves as the primary baseline for memory efficiency.
    \item **(Optional) Sequential C/Rust:** Equivalent sequential implementations in C or Rust compiled with optimizations (`-O2`/`--release`) to provide a performance ceiling reference for the native backend.
\end{itemize}

\section{Results and Analysis} % 4.3 (Was 4.2)
% Present and discuss the results

\subsection{Memory Efficiency Analysis} % 4.3.1 (Was 4.2.1)
[TODO: Present quantitative results (tables/graphs) comparing Parallax memory footprint and churn vs. Bend for each benchmark. Graphs should clearly label axes and units. Use captions to explain each figure/table.]

\textit{Analysis:} The results indicate that Parallax [TODO: Summarize findings, e.g., "consistently achieved lower peak memory usage, averaging X% reduction across benchmarks compared to Bend." or "showed significantly reduced memory churn, particularly for benchmarks involving complex data structures."]. This outcome supports the hypothesis that the memory representation [TODO: Mention specific design choice if relevant, e.g., used in `parallax-net` or managed by `parallax-native` GC] contributes to improved memory behaviour. [TODO: Discuss any anomalies or benchmarks where Parallax did not outperform Bend in memory].

\subsection{Parallel Performance Analysis} % 4.3.2 (Was 4.2.2)
[TODO: Present quantitative results (tables/graphs) showing Parallax execution time vs. core count (1 to max available). Plot Speedup and/or Efficiency curves. Compare against sequential Parallax and potentially Bend/native baselines.]

\textit{Analysis:} The parallel performance results demonstrate that Parallax [TODO: Summarize findings, e.g., "achieves effective parallel scaling up to N cores, showing near-linear speedup for benchmark X but plateauing for benchmark Y due to Z." or "outperforms sequential Parallax significantly, but lags behind the optimized C/Rust baseline."]. The observed scaling behaviour [TODO: Relate to runtime design, e.g., "validates the work-stealing approach for load balancing" or "suggests potential bottlenecks in partition transfer/communication"]. [TODO: Compare scaling against Bend if applicable and data available].

\subsection{Correctness Verification} % 4.3.3 (New Subsection)
Correctness was verified for all benchmarks by [TODO: Describe method, e.g., comparing the final output against the output of the reference sequential implementation]. No correctness issues were detected in the evaluated benchmark runs. [TODO: Optionally, include a small code snippet or description of a simple test case that was verified, as suggested by the guidelines].

\section{Discussion and Interpretation} % 4.4 (Aligned with Mark Scheme, similar to 4.4 in template)
This evaluation provides evidence regarding the success criteria laid out for the Parallax project. The primary goal of improving **memory efficiency** compared to existing interaction net systems like Bend appears to have been [TODO: State conclusion strongly/weakly, e.g., "successfully met", "partially achieved"], supported by the quantitative results presented in Section 4.3.1. This suggests that the design choices focusing on memory layout and potentially the Partition Ownership model (if evaluating `parallax-rt`) are promising directions for interaction net implementation.

The secondary goal of achieving **effective parallel scaling** was also demonstrated (Section 4.3.2), indicating that the automatic parallelization offered by the interaction net model, coupled with the planned runtime architecture, can leverage multi-core hardware. However, [TODO: Acknowledge limitations/gaps, e.g., "the absolute performance compared to highly optimized native code remains a significant gap", or "scaling limitations were observed beyond N cores", or "the evaluation of the `parallax-rt` runtime itself is incomplete"].

Overall, the results [TODO: Provide concluding sentence on the overall success/viability, e.g., "substantiate the claim that Parallax offers a viable approach to achieving more memory-conscious automatic parallelism via interaction nets, although further work is needed on the runtime implementation and absolute performance."]. The project successfully delivered the compiler infrastructure and demonstrated the core concepts, even with the known limitations [TODO: Briefly mention residual issues or incomplete parts like `parallax-rt` if applicable, aligning with the "honest appraisal" requirement].

% \section{Usability Evaluation} % Removed - less focus, integrate brief points into discussion if relevant
% \section{Limitations and Future Work} % Removed - Addressed in Discussion above and detailed in Conclusions chapter

\section{Memory Usage}
% Discuss the memory usage
% - Memory footprint
% - Memory churn
% - Comparison with other approaches

\subsection{Memory Footprint}

\subsection{Memory Churn}

\subsection{Comparison with Other Approaches}

\section{Usability Evaluation}
% Discuss the usability of the language
% - Developer experience
% - Learning curve
% - Productivity

\subsection{Developer Experience}

\subsection{Learning Curve}

\subsection{Productivity Analysis}

\section{Limitations and Future Work}
% Discuss the limitations of the current implementation and future work
% - Current limitations
% - Potential improvements
% - Future research directions

\subsection{Current Limitations}

\subsection{Potential Improvements}

\subsection{Future Research Directions} 